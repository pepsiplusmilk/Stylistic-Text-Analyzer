{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804dc0d1",
   "metadata": {},
   "source": [
    "# Классификация текстов по функциональным стилям (RuBERT + pymorphy3)\n",
    "\n",
    "В данном ноутбуке мы:\n",
    "1. Установим и импортируем необходимые библиотеки.\n",
    "2. Проведём предобработку текстов (очистка + лемматизация с помощью `pymorphy3`).\n",
    "3. Используем модель [RuBERT](https://huggingface.co/DeepPavlov/rubert-base-cased) от DeepPavlov для обучения на задаче классификации текстов.\n",
    "4. Оценим качество на тестовых данных.\n",
    "5. Продемонстрируем применение модели к новым текстам.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c544d",
   "metadata": {},
   "source": [
    "## Шаг 1. Установка необходимых библиотек\n",
    "\n",
    "> **Примечание:** Если вы используете Google Colab или свою локальную среду, где данные библиотеки уже установлены, возможно, ничего дополнительно делать не нужно. Но если возникает ошибка \"No module named ...\", раскомментируйте соответствующие команды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07da160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pymorphy3 transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940be67",
   "metadata": {},
   "source": [
    "## Шаг 2. Импорт и инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44072943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pymorphy3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Инициализируем лемматизатор pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "# Для воспроизводимости\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd1c35",
   "metadata": {},
   "source": [
    "## Шаг 3. Подготовка (сбор) данных\n",
    "В реальном случае вы можете загружать тексты и метки (стили) из CSV/JSON/базы данных. Здесь для примера используем короткий искусственный корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a8bcdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример данных: тексты и их классы (5 стилей)\n",
    "texts = [\n",
    "    \"Изучая квантовую механику, важно понимать принципы неопределённости Гейзенберга.\",\n",
    "    \"Согласно Постановлению №123, гражданам требуется подать заявление до 1 мая.\",\n",
    "    \"Вчера в новостях сообщили о повышении цен на топливо и провели опрос среди населения.\",\n",
    "    \"Привет! Как дела? Давно не виделись, давай созвонимся вечером!\",\n",
    "    \"Утрами морозное солнце красило дворец в ослепительно-пурпурные тона...\",\n",
    "    \"В ходе эксперимента было обнаружено, что данные частиц не совпадают с теоретическими предсказаниями.\",\n",
    "    \"Настоящим подтверждается, что указанный сотрудник состоит в штате на должности менеджера.\",\n",
    "    \"По информации СМИ, на этой неделе состоится конференция по экологическим проблемам.\",\n",
    "    \"Привет, ты уже в городе? Как насчёт встретиться и обсудить планы на выходные?\",\n",
    "    \"Её глаза блестели, а сердце замирало в предчувствии неизведанных дорог.\"\n",
    "]\n",
    "\n",
    "# Метки (0=научный, 1=официально-деловой, 2=публицистический, 3=разговорный, 4=художественный)\n",
    "labels = [\n",
    "    0, 1, 2, 3, 4,\n",
    "    0, 1, 2, 3, 4\n",
    "]\n",
    "\n",
    "len(texts), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cf721",
   "metadata": {},
   "source": [
    "## Шаг 4. Предобработка текстов (очистка + лемматизация через `pymorphy3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98a8669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['изучать квантовый механика важно понимать принцип неопределённость гейзенберг',\n",
       " 'согласно постановление 123 гражданин требоваться подать заявление до 1 май',\n",
       " 'вчера в новость сообщить о повышение цена на топливо и провести опрос среди население',\n",
       " 'привет как дело давно не видеться давать созвониться вечером',\n",
       " 'утро морозный солнце красить дворец в ослепительно пурпурный тон',\n",
       " 'в ход эксперимент быть обнаружить что дать частица не совпадать с теоретический предсказание',\n",
       " 'настоящий подтверждаться что указанный сотрудник состоять в штат на должность менеджер',\n",
       " 'по информация сми на этот неделя состояться конференция по экологический проблема',\n",
       " 'привет ты уже в город как насчёт встретиться и обсудить план на выходной',\n",
       " 'её глаз блестеть а сердце замирать в предчувствие неизведанный дорога']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    # 1) Приводим в нижний регистр\n",
    "    text = text.lower()\n",
    "    # 2) Убираем пунктуацию и нежелательные символы\n",
    "    text = re.sub(r'[\\^\\!\\?\\.,:\\-\\—\\\"№;\\(\\)\\\"\\…\\«\\»]', ' ', text)\n",
    "    # 3) Убираем повторяющиеся пробелы\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # 4) Лемматизируем каждое слово\n",
    "    tokens = text.split()\n",
    "    lemma_tokens = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "    lemmatized_text = ' '.join(lemma_tokens)\n",
    "    return lemmatized_text\n",
    "\n",
    "processed_texts = [preprocess_text(t) for t in texts]\n",
    "processed_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8dcda",
   "metadata": {},
   "source": [
    "## Шаг 5. Разделение на обучающую и тестовую выборки\n",
    "Используем функцию `train_test_split` из scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe69d693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, [3, 1, 2, 0, 4], [1, 0, 3, 4, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    processed_texts,\n",
    "    labels,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "len(X_train), len(X_test), y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bb0e9",
   "metadata": {},
   "source": [
    "## Шаг 6. Создание объектов `Dataset` (Hugging Face) для обучения\n",
    "Чтобы пользоваться `Trainer`, преобразуем данные в формат `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f697b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 5\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 5\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    'text': X_train,\n",
    "    'label': y_train\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': X_test,\n",
    "    'label': y_test\n",
    "})\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095cfee",
   "metadata": {},
   "source": [
    "## Шаг 7. Загрузка токенизатора и модели RuBERT\n",
    "Используем модель [DeepPavlov/rubert-base-cased](https://huggingface.co/DeepPavlov/rubert-base-cased). Зададим `num_labels=5`, чтобы выйти на классификацию по пяти стилям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7b81db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c8fd15b49847618ec7c12ef55baa7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3439579cb62044809d58741b99f545d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eeeae30a54405682ec7a1c04fc7e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a890d3d43a87467896b652867bdf8c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f5a9fd34d74f0986363b68d549aa41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac1f8a36237406da8d9bba4b15ce1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1676a404e794ec7938936b9a2e516c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8cfd99f5244c9692c17e4025d030ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"DeepPavlov/rubert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Функция токенизации для набора данных\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Токенизируем train и test\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True, batch_size=len(train_dataset))\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True, batch_size=len(test_dataset))\n",
    "\n",
    "# Приводим к формату PyTorch\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "num_labels = 5\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33fcfa",
   "metadata": {},
   "source": [
    "## Шаг 8. Настройка `Trainer` и гиперпараметров обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a60feb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_style_rubert_pymorphy3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Пример: 3 эпох\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Батч для обучения\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Батч для валидации\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_metrics\u001b[39m(eval_pred):\n\u001b[32m     17\u001b[39m     logits, labels = eval_pred\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_style_rubert_pymorphy3\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,              # Пример: 3 эпох\n",
    "    per_device_train_batch_size=2,   # Батч для обучения\n",
    "    per_device_eval_batch_size=2,    # Батч для валидации\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    accuracy = (preds == labels).mean()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4888f5b",
   "metadata": {},
   "source": [
    "## Шаг 9. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb13801",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b19415",
   "metadata": {},
   "source": [
    "## Шаг 10. Оценка на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f19eb",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Evaluation results:\", eval_results)\n",
    "\n",
    "# Подробный отчёт\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_label_ids = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "target_names = [\n",
    "    \"Научный\", \n",
    "    \"Официально-деловой\", \n",
    "    \"Публицистический\", \n",
    "    \"Разговорный\", \n",
    "    \"Художественный\"\n",
    "]\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    pred_label_ids,\n",
    "    target_names=target_names\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2526dc7",
   "metadata": {},
   "source": [
    "## Шаг 11. Пример применения модели на новых текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46627fb",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "new_texts = [\n",
    "    \"Данный эксперимент доказывает существование новых возмущений в ядре атома.\",\n",
    "    \"Настоящим уведомляем Вас о необходимости явиться в суд.\",\n",
    "    \"Вчера по телевидению показали репортаж о ситуации с пробками на дорогах.\",\n",
    "    \"Привет! Ты видел последний фильм? Давай обсудим!\",\n",
    "    \"Ветер шептал о грядущих переменах, а утро встречало её ласковым рассветом.\"\n",
    "]\n",
    "\n",
    "# Повторяем ту же схему предобработки\n",
    "new_texts_preprocessed = [preprocess_text(t) for t in new_texts]\n",
    "\n",
    "# Токенизируем\n",
    "encodings = tokenizer(\n",
    "    new_texts_preprocessed,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Прогоняем через модель\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encodings)\n",
    "    logits = outputs.logits\n",
    "    predicted_classes = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "label_map = {\n",
    "    0: \"Научный\",\n",
    "    1: \"Официально-деловой\",\n",
    "    2: \"Публицистический\",\n",
    "    3: \"Разговорный\",\n",
    "    4: \"Художественный\"\n",
    "}\n",
    "\n",
    "print(\"\\nНовые тексты и их стили:\\n\")\n",
    "for text, pred_label in zip(new_texts, predicted_classes):\n",
    "    print(f\"Текст: {text}\\n -> {label_map[pred_label]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a23a8",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "Этот ноутбук аналогичен предыдущему примеру (с `pymorphy2`), но использует **pymorphy3** для лемматизации. В остальном шаги остаются теми же:\n",
    "1. Очистка текста.\n",
    "2. Лемматизация через `pymorphy3.MorphAnalyzer`.\n",
    "3. Токенизация и обучение модели `RuBERT`.\n",
    "4. Оценка и применение к новым текстам.\n",
    "\n",
    "**Возможные улучшения**:\n",
    "- Расширить датасет (для реальной задачи нужно гораздо больше примеров).\n",
    "- Оптимизировать гиперпараметры (число эпох, размер батча, learning rate и т.п.).\n",
    "- Проверять дополнительные метрики (precision, recall, f1) и анализировать результаты.\n",
    "- Применять кросс-валидацию, аугментацию данных и т.д."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
